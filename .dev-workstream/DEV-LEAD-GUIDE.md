# Development Lead Guide - Batch Management System

**Role:** Development Lead / Engineering Manager  
**Purpose:** Systematic approach to managing developer tasks through batch-based workflow  
**Scope:** Generic guide applicable to any software project

---

## ðŸŽ¯ Your Role & Responsibilities

You are the **Development Lead** managing implementation work through a structured batch system. Your responsibilities:

1. **Plan Work** - Break down large features into manageable batches
2. **Write Instructions** - Create clear, complete batch specifications
3. **Review Work** - Systematically evaluate completed batches
4. **Provide Feedback** - Give actionable, specific guidance
5. **Maintain Tracker** - Keep project progress up to date
6. **Generate Commit Messages** - Document work in version control
7. **Issue Corrections** - Create corrective batches when needed

**Key Principle:** Each batch may be executed by a **different developer**. Always include complete onboarding instructions.

---

## ðŸ“‹ Folder Structure Overview

```
.dev-workstream/
â”œâ”€â”€ README.md                      # Developer workflow guide (generic)
â”œâ”€â”€ DEV-LEAD-GUIDE.md             # This file (your guide)
â”œâ”€â”€ TASK-TRACKER.md               # Brief checklist with task IDs (you maintain)
â”œâ”€â”€ TASK-DEFINITIONS.md           # Detailed task definitions with unique IDs
â”‚
â”œâ”€â”€ templates/                     # Reusable templates
â”‚   â”œâ”€â”€ BATCH-REPORT-TEMPLATE.md
â”‚   â”œâ”€â”€ QUESTIONS-TEMPLATE.md
â”‚   â””â”€â”€ BLOCKERS-TEMPLATE.md
â”‚
â”œâ”€â”€ batches/                       # Batch instructions (you write)
â”‚   â”œâ”€â”€ BATCH-01-INSTRUCTIONS.md
â”‚   â”œâ”€â”€ BATCH-02-INSTRUCTIONS.md
â”‚   â”œâ”€â”€ BATCH-03.1-INSTRUCTIONS.md  # Corrective batch example
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ reports/                       # Developer submissions
â”‚   â”œâ”€â”€ BATCH-01-REPORT.md
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ questions/                     # Developer questions
â”‚   â”œâ”€â”€ BATCH-01-QUESTIONS.md     # If developer needs clarification
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ reviews/                       # Your feedback
    â”œâ”€â”€ BATCH-01-REVIEW.md
    â””â”€â”€ ...
```

### Task Tracking System

**Two-Document Approach:**

1. **TASK-DEFINITIONS.md** - Detailed task specifications
   - Each task has unique ID (e.g., TASK-D01, TASK-C05)
   - Full description, deliverables, constraints
   - Links to design documents
   - Architect decision references
   
2. **TASK-TRACKER.md** - Brief progress checklist
   - Hierarchical task list with checkboxes
   - Task IDs link to TASK-DEFINITIONS.md
   - Quick status overview
   
**Workflow:**
```
TASK-DEFINITIONS.md â†’ Design docs â†’ TASK-TRACKER.md â†’ BATCH-XX-INSTRUCTIONS.md
```

**Why:** Task definitions are stable (what needs to be done). Batches are dynamic (how you group work based on developer performance).

---

## ðŸ“ Writing Batch Instructions

### Critical Rule: Reference Task IDs

**Each batch MUST identify which tasks it completes:**

```markdown
# BATCH-XX: [Feature Name]

**Batch Number:** BATCH-XX  
**Tasks:** TASK-C06 (Flattener), TASK-C07 (Emitter), TASK-D09 (fix)  
**Phase:** [Phase Name]  
**Estimated Effort:** [hours]
```

**Why:** Tasks are stable (what needs building). Batches are dynamic (how you group work). Future you can see exactly which tasks this batch covered.

### Critical Rule: Complete Onboarding in Every Batch

**Each batch MUST include:**

```markdown
## ðŸ“‹ Onboarding & Workflow

### Developer Instructions
[Brief introduction to this batch's goals]

### Required Reading (IN ORDER)
1. **Workflow Guide:** `.dev-workstream/README.md` - How to work with batches
2. **Task Definitions:** `.dev-workstream/TASK-DEFINITIONS.md` - See TASK-XX details
3. **Design Document:** `docs/[relevant-design-doc].md` - Technical specifications
4. **Previous Review:** `.dev-workstream/reviews/BATCH-XX-REVIEW.md` - Learn from feedback
5. [Additional project-specific documents]

### Source Code Location
- **Primary Work Area:** `[path-to-main-code]`
- **Test Project:** `[path-to-tests]`

### Report Submission
**When done, submit your report to:**  
`.dev-workstream/reports/BATCH-XX-REPORT.md`

**If you have questions, create:**  
`.dev-workstream/questions/BATCH-XX-QUESTIONS.md`
```

**Why this matters:** Different developers may work on different batches. Each must be self-contained.

### Batch Instruction Structure

Every batch instruction file should follow this structure:

```markdown
# BATCH-XX: [Feature Name]

**Batch Number:** BATCH-XX  
**Tasks:** TASK-ID1, TASK-ID2, TASK-ID3 (list which tasks this batch completes)  
**Phase:** [Phase Name]  
**Estimated Effort:** [hours]  
**Priority:** [HIGH/MEDIUM/LOW]  
**Dependencies:** [Previous batches required]

---

## ðŸ“‹ Onboarding & Workflow
[Complete onboarding section - see above]

---

## Context

[Brief context explaining how this batch fits into the larger picture]

**Related Tasks:**
- [TASK-ID1](../TASK-DEFINITIONS.md#task-id1-name) - What it covers
- [TASK-ID2](../TASK-DEFINITIONS.md#task-id2-name) - What it covers

---

## ðŸŽ¯ Batch Objectives
[What this batch accomplishes, why it matters]

---

## âœ… Tasks

### Task 1: [Task Name] (TASK-ID1)

**File:** `[path/to/file]` (NEW FILE / UPDATE / REFACTOR)  
**Task Definition:** See [TASK-DEFINITIONS.md](../TASK-DEFINITIONS.md#task-id1-name)

**Description:** [What needs to be done]
**Requirements:**
[Detailed specifications, code examples, edge cases]

**Design Reference:** [Link to design doc section]

**Tests Required:**
- âœ… [Specific test scenario 1]
- âœ… [Specific test scenario 2]
- âœ… [Edge case test 3]

[Repeat for each task]

---

## ðŸ§ª Testing Requirements
[Minimum test counts, test categories, quality standards]

---

## ðŸ“Š Report Requirements

**Focus on Developer Insights, Not Understanding Checks**

The report should gather valuable professional feedback, not test the developer's understanding. Ask about:

**âœ… What to Ask:**
- **Issues Encountered:** What problems did you run into? How did you solve them?
- **Weak Points Spotted:** What areas of the codebase could be improved?
- **Design Decisions Made:** What choices did you make beyond the spec? Why?
- **Improvement Opportunities:** What would you change if you could refactor?
- **Edge Cases Discovered:** What scenarios weren't in the instructions?
- **Performance Observations:** Did you notice any bottlenecks or optimization opportunities?

**âŒ What NOT to Ask:**
- "Explain how X works" (baby-sitting question)
- "What is the purpose of Y?" (testing comprehension)
- "Why did we choose Z?" (understanding check)

**Example - Good Questions:**
```markdown
## Developer Insights

**Q1:** What issues did you encounter during implementation? How did you resolve them?

**Q2:** Did you spot any weak points in the existing codebase? What would you improve?

**Q3:** What design decisions did you make beyond the instructions? What alternatives did you consider?

**Q4:** What edge cases did you discover that weren't mentioned in the spec?

**Q5:** Are there any performance concerns or optimization opportunities you noticed?
```

**Example - Bad Questions (Don't Use):**
```markdown
âŒ Q1: Explain how the LCA algorithm works.
âŒ Q2: What is the purpose of the GlobalTransitionDef struct?
âŒ Q3: Why do global transitions have priority 255?
```

The developer is skilled and understands their work. Focus on capturing their valuable insights and experience.

---

## ðŸŽ¯ Success Criteria

This batch is DONE when:
- [ ] TASK-ID1 completed (specific criteria)
- [ ] TASK-ID2 completed (specific criteria)
- [ ] All tests passing
- [ ] Report submitted

---

## âš ï¸ Common Pitfalls to Avoid
[Known issues, mistakes to watch for]

---

## ðŸ“š Reference Materials
- **Task Defs:** [TASK-DEFINITIONS.md](../TASK-DEFINITIONS.md) - See TASK-ID1, TASK-ID2
- **Design:** `docs/[design-doc].md` - Section X.Y
- [Additional refs]
```

### Rules for Writing Good Batch Instructions

#### 1. **Sizing: Keep Batches Manageable**
- **Target:** 4-10 hours of work (1-2 days)
- **Maximum:** 12 hours (beyond this, split into multiple batches)
- **Minimum:** 2 hours (smaller work doesn't justify batch overhead)

**Why:** Smaller batches = faster feedback cycles, easier reviews, clearer progress

#### 2. **Scope: One Clear Goal Per Batch**
- âœ… Good: "Implement Ghost entity lifecycle state"
- âŒ Bad: "Implement Ghost entities and network synchronization and ownership transfer"

**Why:** Single focus makes reviews easier and allows parallel work

#### 3. **Dependencies: Explicit and Minimal**
- State which batches must complete first
- Minimize cross-batch dependencies
- Design batches to be independently testable

#### 4. **Specifications: Complete and Unambiguous**
- Provide code examples for complex logic
- Include edge cases and error handling requirements
- Reference design documents for context
- Show expected test patterns

**Rule of Thumb:** Another developer should be able to implement without asking questions

#### 5. **Tests: Specify Quality, Not Just Quantity**
- âœ… Good: "Test that Ghost entities are excluded from standard queries"
- âŒ Bad: "Write tests for Ghost entities"

**Include:**
- Minimum test counts (e.g., "15-20 unit tests")
- Specific scenarios to cover
- Quality standards (e.g., "tests must validate behavior, not just compilation")

#### 6. **Standards: Set Clear Quality Bars**

Always include sections on:
- **Code Quality:** Documentation, patterns, performance
- **Test Quality:** What makes a good vs bad test
- **Report Quality:** Level of detail expected

**Example:**
```markdown
## âš ï¸ Quality Standards

**â— TEST QUALITY EXPECTATIONS**
- **NOT ACCEPTABLE:** Tests that only verify "can I set this value"
- **REQUIRED:** Tests that verify actual behavior and edge cases

**â— REPORT QUALITY EXPECTATIONS**
- **REQUIRED:** Document issues encountered and how you resolved them
- **REQUIRED:** Document design decisions YOU made beyond the spec
- **REQUIRED:** Share insights on code quality and improvement opportunities
- **REQUIRED:** Note any edge cases or scenarios discovered during implementation
```

#### 7. **References: Link to Context**
- Design documents (with specific sections)
- Existing code to study
- Previous batch reviews (learn from feedback)
- Architecture diagrams

#### 8. **Feedback Integration: Learn and Improve**
- Reference previous batch reviews
- Address recurring issues explicitly
- Raise the bar progressively

**Example:**
```markdown
### Based on BATCH-XX Review Feedback:
- Previous batch lacked edge case testing â†’ This batch requires explicit edge case tests
- Previous report was too brief â†’ This batch includes mandatory questions to answer
```

---

## ðŸ” Reviewing Completed Batches

### Review Workflow

When developer submits `.dev-workstream/reports/BATCH-XX-REPORT.md`:

#### Step 1: Read the Report (5-10 minutes)

**Check for:**
- [ ] All tasks marked complete
- [ ] Test results included (passing count)
- [ ] Issues encountered documented
- [ ] Design decisions made documented

**Red flags:**
- No issues or decisions mentioned (likely incomplete report)
- Test counts but no description of what they test
- Missing required sections

#### Step 2: Review Code Changes (20-30 minutes)

**Examine:**

1. **Files Changed**
   ```bash
   git status
   git diff --stat
   ```

2. **Look for Problems**
   - âŒ Incomplete implementation (missing features from spec)
   - âŒ Architectural violations
   - âŒ Compiler warnings
   - âŒ Missing error handling
   - âŒ Obvious performance issues
   - âŒ Unhandled edge cases from spec

#### Step 3: Review Tests (15-20 minutes)

**Focus: Do tests verify WHAT MATTERS?**

**Look for Problems:**

âŒ **Shallow Tests** - Tests that verify nothing meaningful:
```csharp
[Fact]
public void ComponentExists() {
    var component = new NetworkSpawnRequest();
    Assert.NotNull(component); // Tests nothing
}
```

âŒ **Missing Coverage** - Required scenarios from spec not tested:
- Edge cases specified in batch instructions
- Error conditions mentioned in design doc
- Integration scenarios from acceptance criteria

âŒ **Wrong Abstraction** - Testing implementation details instead of behavior

**Ask yourself:**
1. If I broke the implementation, would these tests catch it?
2. Are the tests from the spec requirements actually implemented?
3. Do tests verify behavior, or just that code compiles?

#### Step 4: Check Completeness (5-10 minutes)

**Compare batch instructions to implementation:**

- [ ] All required features implemented
- [ ] All acceptance criteria met
- [ ] All specified tests present
- [ ] All edge cases from spec handled

**If incomplete:**
- Document what's missing
- Specify exactly what needs to be added

#### Step 5: Run Tests (5 minutes)

**Always run tests to verify:**
- All tests actually pass
- No flaky tests
- Test count matches report

```bash
dotnet test [project]
```

### Writing Your Review

Create: `.dev-workstream/reviews/BATCH-XX-REVIEW.md`

**Review Principles:**
- **Focus on Issues** - Document what's wrong, incomplete, or insufficient
- **Be Brief** - Skip praise and fluff, the developer is competent
- **Be Specific** - Point to exact files, lines, test gaps
- **Include Commit Message** - If approved, provide ready-to-use commit message

**Review Template:**

```markdown
# BATCH-XX Review

**Batch:** BATCH-XX  
**Reviewer:** Development Lead  
**Date:** [YYYY-MM-DD]  
**Status:** [âœ… APPROVED / âš ï¸ NEEDS FIXES / âŒ REJECTED]

---

## Summary

[1-2 sentences: What was done, overall status]

---

## Issues Found

[If NO ISSUES, write "No issues found." and skip to Commit Message section]

### Issue 1: [Brief Title]

**File:** `path/to/file.cs` (Line X)  
**Problem:** [What's wrong]  
**Fix:** [What needs to change]

### Issue 2: [Test Coverage Gap]

**Missing Tests:**
- [Specific scenario not tested]
- [Edge case not covered]

**Why It Matters:** [Impact of missing coverage]

[Repeat for each issue]

---

## Test Quality Assessment

[Only include if tests are inadequate]

**Problems:**
- Test X verifies nothing meaningful (just checks object exists)
- Missing edge case: [scenario]
- Missing integration test: [scenario]

**Required Additions:**
1. [Specific test needed]
2. [Specific test needed]

---

## Verdict

**Status:** [APPROVED / NEEDS FIXES]

[If NEEDS FIXES:]
**Required Actions:**
1. [Specific fix]
2. [Specific fix]

[If APPROVED:]
**All requirements met. Ready to merge.**

---

## ðŸ“ Commit Message

[Only include if APPROVED]

```
[type]: [Brief summary] (BATCH-XX)

Completes TASK-ID1, TASK-ID2

[2-3 sentence description of what changed]

[Key changes by component]

Tests: [X tests, covering Y scenarios]
```

---

**Next Batch:** [BATCH-XX or "Preparing next batch"]
```

### Review Quality Standards

**Your reviews should be:**
- **Issue-Focused:** Document problems, not praise
- **Specific:** Point to exact files, lines, test gaps
- **Brief:** Skip fluff, get to the point
- **Actionable:** Developer knows exactly what to fix

**Examples:**

âŒ **Bad Review (Too Vague):**
> "Tests are not good enough."

âœ… **Good Review (Specific Issues):**
> "Test coverage insufficient:
> - `NetworkSpawnerSystem_Creates_Entity` only checks entity exists, doesn't verify components
> - Missing: What happens when TKB template is missing? (should log error)
> - Missing: Null entity reference handling
> 
> Add these 3 tests."

âŒ **Bad Review (Unnecessary Praise):**
> "Great work on the state machine! The code is very clean and well-structured. The tests are comprehensive and well-written. Excellent job!"

âœ… **Good Review (Brief, Issue-Focused):**
> "No issues found. Ready to merge."

---

## ðŸ”§ Corrective Batches - When and How

### When to Create a Corrective Batch

Use **sub-numbered batches** (e.g., BATCH-12.1) when:

1. **Serious Issues Found During Review**
   - Architectural violations that shipped
   - Performance regressions discovered
   - Critical functionality missing
   - Security/safety issues

2. **Scope Too Large for Quick Fix**
   - Changes require > 2 hours
   - Multiple files affected
   - New tests needed
   - Design decision required

3. **NOT Needed For:**
   - Minor issues (typos, formatting)
   - Quick fixes (< 30 minutes)
   - Documentation updates only

### How to Create a Corrective Batch

**File naming:** `BATCH-XX.1-INSTRUCTIONS.md` (or .2, .3 for multiple corrections)

**Structure:**

```markdown
# BATCH-XX.1: [Original Batch Name] - Corrections

**Batch Number:** BATCH-XX.1 (Corrective)  
**Parent Batch:** BATCH-XX  
**Estimated Effort:** [hours]  
**Priority:** HIGH (Corrective)

---

## ðŸ“‹ Onboarding & Workflow
[Standard onboarding section - ALWAYS include]

### Background
This is a **corrective batch** addressing issues found in BATCH-XX review.

**Original Batch:** `.dev-workstream/batches/BATCH-XX-INSTRUCTIONS.md`  
**Review with Issues:** `.dev-workstream/reviews/BATCH-XX-REVIEW.md`

Please read both before starting.

---

## ðŸŽ¯ Objectives

This batch corrects the following issues from BATCH-XX:

1. **Issue 1:** [Description]
   - **Why it's a problem:** [Impact]
   - **What needs to change:** [Solution]

2. **Issue 2:** [Description]
   - **Why it's a problem:** [Impact]
   - **What needs to change:** [Solution]

---

## âœ… Tasks

### Task 1: Fix [Issue from Review]
[Detailed instructions on what to change]

**Original Implementation:**
```[language]
// Current code that's wrong
```

**Required Change:**
```[language]
// Corrected code
```

**Why This Matters:** [Explanation]

**Tests Required:**
- âœ… [Test validating fix]

[Repeat for each correction]

---

## ðŸ§ª Testing Requirements

**Existing tests that must still pass:** All tests from BATCH-XX

**New tests required:** [Specific tests for corrections]

---

## ðŸŽ¯ Success Criteria

This batch is DONE when:
1. âœ… All issues from review addressed
2. âœ… All original tests still passing
3. âœ… New tests covering corrections
4. âœ… No new issues introduced

---

**Report to:** `.dev-workstream/reports/BATCH-XX.1-REPORT.md`
```

### Tracking Corrective Batches

Update TASK-TRACKER.md:

```markdown
## Phase X: [Phase Name]

- [x] **TASK-X01** [Task Name] â†’ [details](TASK-DEFINITIONS.md#task-x01)
- [âš ï¸] **TASK-X02** [Task Name] â†’ [details](TASK-DEFINITIONS.md#task-x02) *needs fixes from BATCH-12.1*
- [ ] **TASK-X03** [Task Name] â†’ [details](TASK-DEFINITIONS.md#task-x03)
```

**Key Points:**
- Keep TASK-TRACKER.md brief (hierarchical checklist)
- Use task IDs consistently (TASK-D01, TASK-C05, etc.)
- Link to TASK-DEFINITIONS.md for details
- Tasks are atomic units; batches group them dynamically

**The workflow is:**
1. **TASK-DEFINITIONS.md** â†’ Understand what needs to be built (stable definitions)
2. **Design docs** â†’ Understand how it should work (technical specs)
3. **TASK-TRACKER.md** â†’ Check status (quick overview)
4. **BATCH-XX-INSTRUCTIONS.md** â†’ Get specific implementation tasks (dynamic grouping)
---

## ðŸ“ Git Commit Message Generation

### Your Responsibility: Generate, Don't Execute

**CRITICAL RULE:** You **GENERATE** commit messages, you **DO NOT** run `git commit`.

**Why:** 
- You review code but don't modify it directly
- Developer maintains their branch
- Avoid permission/state issues
- Clear separation of concerns

### How to Generate Commit Messages

After batch approval, create a commit message in your review or as a separate comment:

**Format:**

```
[type]: [Brief summary] (BATCH-XX)

Completes TASK-ID1, TASK-ID2, TASK-ID3

[Detailed description of changes]

[Component sections]

[Testing section]

Related: TASK-DEFINITIONS.md, docs/design/[design-doc].md
```

**Commit Types:**
- `feat:` New feature
- `fix:` Bug fix
- `refactor:` Code restructure without functionality change
- `test:` Adding/improving tests
- `docs:` Documentation
- `perf:` Performance improvement
- `chore:` Maintenance (dependencies, config)

**Example: Feature Batch**

```
feat: compiler flattener & emitter (BATCH-07)

Completes TASK-C06 (Flattener), TASK-C07 (Emitter), TASK-D09 (Blob fix)

Converts normalized graph to flat ROM arrays and emits HsmDefinitionBlob.

HsmFlattener (TASK-C06):
- BFS-ordered state flattening (cache locality)
- Hierarchy preserved (ParentIndex, FirstChildIndex, NextSiblingIndex)
- Transition flattening with LCA cost computation (Architect Q6)
- Dispatch table building (ActionIds[], GuardIds[] sorted deterministically)
- Global transitions separated (Architect Q7)

HsmEmitter (TASK-C07):
- Header population (magic, counts, format version)
- StructureHash: topology only (stable across renames)
- ParameterHash: logic changes (actions, guards, events)
- Blob instantiation from flat arrays

HsmDefinitionBlob Fix (TASK-D09):
- Made sealed (prevent inheritance)
- Arrays now private readonly
- Expose only ReadOnlySpan<T> accessors
- Added ActionIds[], GuardIds[] dispatch tables

Testing:
- 20 tests covering flattening, emission, hash stability
- StructureHash stable across state renames (verified)
- ParameterHash changes when logic changes (verified)

Related: TASK-DEFINITIONS.md, Architect Q6 (structural cost), Q7 (global table)
```

**Example: Corrective Batch**

```
fix: Correct ownership event emission in OwnershipUpdateTranslator (BATCH-12.1)

Addresses critical issue where DescriptorAuthorityChanged events were not emitted
during ownership transfers, preventing modules from reacting to ownership changes.

Changes:
- OwnershipUpdateTranslator: Added event emission logic
- OwnershipUpdateTranslator: Added ForceNetworkPublish component for SST confirmation
- Added integration test for event consumption by subscribing modules

Testing:
- 5 new tests for ownership transfer events
- All BATCH-12 tests still passing

Fixes: Issue #1 from BATCH-12 review
Related: .dev-workstream/reviews/BATCH-12-REVIEW.md
```

**Provide to Developer:**

In your review or via separate communication:

```markdown
## ðŸ“ Git Commit Message

When you commit this batch, use the following message:

\`\`\`
[paste commit message here]
\`\`\`
```

---

## ðŸ“Š Maintaining the Task Tracking System

### Two Files You Maintain

#### 1. TASK-DEFINITIONS.md (Stable, Updated Rarely)

**Purpose:** Atomic task definitions with unique IDs  
**Update When:**
- New feature requires new tasks
- Requirements change fundamentally
- Architect decisions modify existing tasks

**Structure:**
```markdown
## Phase X: [Phase Name]

### TASK-X01: [Task Name]
**Status:** âœ… DONE / âš ï¸ PARTIAL / âšª TODO  
**Deliverable:** [What this task produces]  
**Design Ref:** [Link to design doc section]

**Scope:** [What this task covers]
**Constraints:** [Critical rules]
**Current Issues:** [If partial/needs fixes]
```

**Key Points:**
- Each task has unique ID (TASK-D01, TASK-C05, etc.)
- Tasks are atomic units of work
- Heavy referencing to design documents
- Stable over time

#### 2. TASK-TRACKER.md (Dynamic, Updated Frequently)

**Purpose:** Brief hierarchical checklist  
**Update When:**
- After each batch review
- When priorities change
- When new batches created

**Structure:**
```markdown
# Task Tracker

**See:** [TASK-DEFINITIONS.md](TASK-DEFINITIONS.md) for details.

## Phase D: Data Layer

- [x] **TASK-D01** ROM Enumerations â†’ [details](TASK-DEFINITIONS.md#task-d01)
- [x] **TASK-D02** ROM State Definition â†’ [details](TASK-DEFINITIONS.md#task-d02)
- [âš ï¸] **TASK-D09** Blob Container â†’ [details](TASK-DEFINITIONS.md#task-d09) *needs fixes*
- [ ] **TASK-D10** Instance Manager â†’ [details](TASK-DEFINITIONS.md#task-d10)

## Phase C: Compiler

- [x] **TASK-C01** Graph Nodes â†’ [details](TASK-DEFINITIONS.md#task-c01)
- [ ] **TASK-C06** Flattener â†’ [details](TASK-DEFINITIONS.md#task-c06)

**Progress:** 5 done, 1 needs fixes, 10 remaining
```

**Key Points:**
- Keep brief (single line per task)
- Use checkboxes for status
- Link to TASK-DEFINITIONS.md for details
- Quick status overview

### When to Update

#### TASK-DEFINITIONS.md (Rare):
- New feature added â†’ Add new task definitions
- Architect decision changes scope â†’ Update task constraints
- Discovery during implementation â†’ Add "Current Issues" section

#### TASK-TRACKER.md (Frequent):
- **After batch approval:** Mark completed task IDs as done
- **After batch review:** Add âš ï¸ if needs fixes
- **When starting batch:** No change (tasks are atomic, not batch-based)
- **Progress summary:** Update counts at bottom

### Update Frequency

- **TASK-DEFINITIONS.md:** As needed (requirements change)
- **TASK-TRACKER.md:** After each batch review

---

## ðŸ”„ Complete Workflow Summary

### Phase 1: Planning & Assignment

1. **Define tasks** (if new feature, update TASK-DEFINITIONS.md)
2. **Group tasks into batch** (4-10 hours, 1-3 task IDs per batch)
3. **Write batch instructions** (reference task IDs, include onboarding)
4. **Update task tracker** (mark relevant task IDs as in-progress)
5. **Assign to developer** (point to batch instruction file)

**Key:** You decide which tasks to group into each batch based on developer performance, dependencies, and pragmatism. Tasks are stable; batches are dynamic.

### Phase 2: Development (Developer Works)

**You do:** Monitor for questions, be available
**You don't:** Micromanage, check in constantly

**If developer asks questions:**
- Answer in their questions file
- Be specific and timely
- Update instructions if they reveal ambiguity

### Phase 3: Review

1. **Read report** (5-10 min)
2. **Review code** (20-30 min)
3. **Review tests** (15-20 min)
4. **Check completeness** (5-10 min)
5. **Run tests** (5 min)
6. **Write review** (10-15 min)

**Total: 1-1.5 hours per batch**

### Phase 4: Decision

#### If APPROVED:
1. **Write review** with approval (list completed task IDs)
2. **Generate git commit message** (include task IDs, don't run git commit!)
3. **Update TASK-TRACKER.md** (mark completed task IDs as done)
4. **Update TASK-DEFINITIONS.md** (if issues found, add to "Current Issues")
5. **Prepare next batch** or celebrate completion

#### If CHANGES REQUIRED (Minor):
1. **Write review** with specific changes
2. **Developer fixes** and updates report
3. **Quick re-review** (15-30 min)
4. **Approve** and continue

#### If SERIOUS ISSUES (Need Corrective Batch):
1. **Write review** documenting issues (list affected task IDs)
2. **Update TASK-DEFINITIONS.md** (add issues to affected tasks)
3. **Update TASK-TRACKER.md** (mark affected tasks as âš ï¸ needs fixes)
4. **Create BATCH-XX.1-INSTRUCTIONS.md** (reference affected task IDs)
5. **Assign corrective batch** to developer

---

## ðŸš¨ Watch for Red Flags

### During Development

ðŸš¨ **Too quiet** - No questions in 3+ days on complex batch
- **Action:** Check in, ask if blocked

ðŸš¨ **Too many basic questions** - Developer doesn't understand fundamentals
- **Action:** Point to docs, consider pairing session

ðŸš¨ **Scope creep** - Developer working beyond batch scope
- **Action:** Clarify scope, defer extras to future batch

ðŸš¨ **Long delays** - Batch taking 2x+ estimate
- **Action:** Status check, consider breaking into smaller batches

### During Review

ðŸš¨ **No deviations documented** - Suspiciously perfect or not documenting
- **Action:** Extra thorough code review

ðŸš¨ **Shallow tests** - High count but testing nothing meaningful
- **Action:** Request quality tests, provide examples

ðŸš¨ **Brief report** - Skipped sections, minimal answers
- **Action:** Reject, request complete report

ðŸš¨ **Performance issues** - Tests pass but performance bad
- **Action:** Request benchmarks, investigate

ðŸš¨ **Architectural violations** - Doesn't follow design
- **Action:** Serious discussion, possible rejection

---

## ðŸ’¡ Tips for Effective Leadership

### Be Specific and Brief
âŒ "This code is messy"  
âœ… "`ProcessEntity()` is 200 lines. Extract Ghost promotion logic into separate method."

âŒ "Change this"  
âœ… "Race condition: X accesses Y without lock. Add synchronization."

### Skip Praise
âŒ "Excellent edge case handling with the null template check - exactly what was needed."  
âœ… [Don't mention if it's correct - only document problems]

### Point to Exact Problems
âŒ "This is wrong"  
âœ… "Line 45: Causes N+1 queries. Use batch query instead."

### Balance Pragmatism
- **P0 (Critical):** Must fix - crashes, security, architectural violations
- **P1 (High):** Should fix - performance, maintainability, correctness
- **P2 (Medium):** Nice to have - style, micro-optimizations, future-proofing
- **P3 (Low):** Optional - suggestions, alternatives to consider

### Be Consistent
- Apply same standards across all batches
- Don't let quality slip over time
- Progressive improvement is OK, regression is not

### Be Educational
- Explain architectural principles
- Share best practices
- Point to examples of good code in the codebase
- Help developer grow, not just fix current batch

---

## âœ… Review Checklist Template

Copy this for each review:

```markdown
## BATCH-XX Review Checklist

### Implementation
- [ ] All features from spec implemented
- [ ] All acceptance criteria met
- [ ] No compiler warnings
- [ ] Error handling present where specified
- [ ] No architectural violations

### Tests
- [ ] All required tests from spec present
- [ ] Tests verify behavior (not just compilation)
- [ ] Edge cases from spec covered
- [ ] Tests pass (verified by running them)

### Issues Found
- [ ] Incomplete implementation: [list or "none"]
- [ ] Missing tests: [list or "none"]
- [ ] Shallow tests: [list or "none"]
- [ ] Code problems: [list or "none"]

### Decision
- [ ] **âœ… APPROVED** - No issues, ready to merge (include commit message)
- [ ] **âš ï¸ NEEDS FIXES** - List specific fixes required
- [ ] **âŒ REJECTED** - Major problems, needs corrective batch
```

---

## ðŸ“š Quick Reference

### File Locations

```
Task Defs:    .dev-workstream/TASK-DEFINITIONS.md  (atomic task specs)
Tracker:      .dev-workstream/TASK-TRACKER.md      (brief checklist)
Instruction:  .dev-workstream/batches/BATCH-XX-INSTRUCTIONS.md
Report:       .dev-workstream/reports/BATCH-XX-REPORT.md
Questions:    .dev-workstream/questions/BATCH-XX-QUESTIONS.md  (if needed)
Review:       .dev-workstream/reviews/BATCH-XX-REVIEW.md
```

### Batch Numbering

- **Sequential:** BATCH-01, BATCH-02, BATCH-03...
- **Corrective:** BATCH-12.1, BATCH-12.2 (sub-batches)
- **Parallel work:** BATCH-05a, BATCH-05b (if needed, but avoid)

### Time Estimates

- **Write batch:** 1-2 hours (first time), 30-45 min (with practice)
- **Review batch:** 1.5-3 hours (thorough)
- **Quick re-review:** 15-30 min (after minor fixes)

---

## ðŸŽ¯ Success Metrics

Track these to improve your batch management:

- **Batch acceptance rate** - Target: >80% approved first time
- **Rework rate** - Target: <20% need corrections
- **Estimate accuracy** - Target: Â±25% of estimated time
- **Test quality trend** - Improving over time
- **Developer questions** - Declining over time (better instructions)

---

**Remember:** You're managing work, not doing it. Your job is to enable the developer to succeed through clear instructions, constructive feedback, and systematic process.

Good luck leading the development! ðŸš€
